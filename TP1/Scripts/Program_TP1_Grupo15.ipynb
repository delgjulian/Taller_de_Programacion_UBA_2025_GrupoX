{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96013f42-032e-4407-883f-522443881bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"module://matplotlib_inline.backend_inline\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"‚úÖ Entorno Jupyter funcionando correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee342fe-f15d-42b1-8e5f-ce9d11da3251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CARGA DE MICRODATOS EPH - Primer trimestre 2005 ===\n",
    "\n",
    "# Ruta del archivo .dta (ajustada a tu PC)\n",
    "ruta = r\"C:\\Users\\julla\\Downloads\\Datos\\Individual_t105.dta\"\n",
    "\n",
    "# Cargar base con pandas\n",
    "df = pd.read_stata(ruta)\n",
    "\n",
    "# Vista general\n",
    "print(\"‚úÖ Base cargada correctamente\")\n",
    "print(\"Filas y columnas:\", df.shape)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f16f23-464c-4931-abcf-5df2bda38048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informaci√≥n general\n",
    "df.info()\n",
    "\n",
    "# Variables disponibles\n",
    "print(\"\\nColumnas disponibles:\\n\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Vista r√°pida de los valores √∫nicos en algunas columnas clave\n",
    "cols_principales = ['CH04', 'CH06', 'CAT_OCUP', 'ESTADO', 'NIVEL_ED', 'P47T']\n",
    "for col in cols_principales:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col}: {df[col].unique()[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625c16fc-73c7-41a3-9bd8-a4119f078b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CARGA DE MICRODATOS EPH - Primer trimestre 2025 ===\n",
    "\n",
    "# Ruta del archivo .txt\n",
    "ruta_2025 = r\"C:\\Users\\julla\\Downloads\\Datos\\usu_individual_T125.txt\"\n",
    "\n",
    "# Cargar base (delimitador punto y coma)\n",
    "df_2025 = pd.read_csv(ruta_2025, sep=';', encoding='latin-1', low_memory=False)\n",
    "\n",
    "# Vista general\n",
    "print(\"‚úÖ Base 2025 cargada correctamente desde TXT\")\n",
    "print(\"Filas y columnas:\", df_2025.shape)\n",
    "df_2025.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96794871-6783-4f6d-9544-44f5fde2eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columnas 2005:\", len(df.columns))\n",
    "print(\"Columnas 2025:\", len(df_2025.columns))\n",
    "\n",
    "# Coincidencia de nombres\n",
    "cols_2005 = set(df.columns)\n",
    "cols_2025 = set(df_2025.columns)\n",
    "coincidentes = cols_2005.intersection(cols_2025)\n",
    "print(\"\\nVariables coincidentes entre 2005 y 2025:\", len(coincidentes))\n",
    "print(sorted(list(coincidentes))[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52accd74-94e4-4bfe-bf76-bee03ae0f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Normalizar nombres de columnas ===\n",
    "df_2025.columns = df_2025.columns.str.lower()  # pasar todo a min√∫sculas\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "# Verificar coincidencias nuevamente\n",
    "cols_2005 = set(df.columns)\n",
    "cols_2025 = set(df_2025.columns)\n",
    "coincidentes = cols_2005.intersection(cols_2025)\n",
    "\n",
    "print(\"üîÅ Variables coincidentes entre 2005 y 2025:\", len(coincidentes))\n",
    "print(sorted(list(coincidentes))[:25])  # muestra las primeras 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e1a74-3035-43e0-a06b-03f00b3d82a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === AGREGAR VARIABLE DE A√ëO Y UNIFICAR BASES ===\n",
    "\n",
    "# Crear variable de a√±o\n",
    "df[\"anio\"] = 2005\n",
    "df_2025[\"anio\"] = 2025\n",
    "\n",
    "# Conservar solo columnas comunes\n",
    "cols_comunes = list(coincidentes)\n",
    "\n",
    "# Unir ambas bases (una sobre otra)\n",
    "df_union = pd.concat([df[cols_comunes + [\"anio\"]], df_2025[cols_comunes + [\"anio\"]]], axis=0)\n",
    "\n",
    "# Resumen\n",
    "print(\"‚úÖ Base combinada creada correctamente\")\n",
    "print(\"Filas totales:\", df_union.shape[0])\n",
    "print(\"Columnas totales:\", df_union.shape[1])\n",
    "print(\"\\nA√±os disponibles:\", df_union[\"anio\"].unique())\n",
    "df_union.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8beceb-89e7-4f89-a0cd-d5876820e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a6ec71-36c4-443f-8730-502a3f039b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === AN√ÅLISIS DE VALORES FALTANTES (Parte I.b) ===\n",
    "import missingno as msno\n",
    "\n",
    "# Calcular porcentaje de valores faltantes por variable\n",
    "faltantes = df_union.isnull().mean() * 100\n",
    "faltantes = faltantes.sort_values(ascending=False)\n",
    "\n",
    "print(\"üîç Porcentaje de valores faltantes por variable (top 15):\")\n",
    "print(faltantes.head(15))\n",
    "\n",
    "# Visualizaci√≥n general de completitud\n",
    "msno.matrix(df_union.sample(1000, random_state=1))  # muestra 1000 registros al azar\n",
    "plt.title(\"üî¢ Patr√≥n de valores faltantes - muestra de 1000 observaciones\")\n",
    "plt.show()\n",
    "\n",
    "# Heatmap de correlaci√≥n de faltantes\n",
    "msno.heatmap(df_union)\n",
    "plt.title(\"üî• Correlaci√≥n de valores faltantes entre variables\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e04fb4d-ea3f-4a54-8283-1c8e5846e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PARTE I.c - Selecci√≥n y limpieza de variables de inter√©s ===\n",
    "\n",
    "# 15 variables clave (seg√∫n consigna y relevancia socioecon√≥mica)\n",
    "vars_interes = [\n",
    "    'ch04',   # Sexo\n",
    "    'ch06',   # Edad\n",
    "    'ch07',   # Estado civil\n",
    "    'ch08',   # Parentesco\n",
    "    'nivel_ed',   # Nivel educativo\n",
    "    'estado',     # Condici√≥n de actividad\n",
    "    'cat_inac',   # Categor√≠a de inactividad\n",
    "    'cat_ocup',   # Categor√≠a ocupacional\n",
    "    'ipcf',       # Ingreso per c√°pita familiar\n",
    "    'pp07g1',     # Ingreso laboral 1\n",
    "    'pp07g2',     # Ingreso laboral 2\n",
    "    'pp07h',      # Total de ingresos laborales\n",
    "    'pp08d',      # Ingreso no laboral\n",
    "    'pp08h',      # Total de ingresos del hogar\n",
    "    'anio'        # A√±o de referencia\n",
    "]\n",
    "\n",
    "# Filtrar solo las variables disponibles\n",
    "vars_presentes = [v for v in vars_interes if v in df_union.columns]\n",
    "df_sel = df_union[vars_presentes].copy()\n",
    "\n",
    "print(f\"Variables seleccionadas ({len(vars_presentes)}): {vars_presentes}\")\n",
    "print(\"Filas iniciales:\", df_sel.shape[0])\n",
    "\n",
    "# Revisi√≥n de valores an√≥malos\n",
    "for col in ['ipcf', 'pp07g1', 'pp07g2', 'pp07h', 'pp08d', 'pp08h']:\n",
    "    if col in df_sel.columns:\n",
    "        print(f\"\\n{col} - Valores √∫nicos problem√°ticos:\")\n",
    "        print(df_sel[col].value_counts().head(10))\n",
    "\n",
    "# Limpieza: eliminar negativos y codificaciones err√≥neas\n",
    "for col in ['ipcf', 'pp07g1', 'pp07g2', 'pp07h', 'pp08d', 'pp08h']:\n",
    "    if col in df_sel.columns:\n",
    "        df_sel[col] = pd.to_numeric(df_sel[col], errors='coerce')  # asegurar tipo num√©rico\n",
    "        df_sel.loc[df_sel[col] < 0, col] = np.nan  # eliminar negativos\n",
    "\n",
    "# Confirmar limpieza\n",
    "print(\"\\n‚úÖ Limpieza completada.\")\n",
    "print(\"Filas finales:\", df_sel.shape[0])\n",
    "df_sel.describe(include='all').T.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9462e74a-ea61-488f-9b2a-ccb8e0332cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Limpieza adicional de variables de ingreso ===\n",
    "\n",
    "# Reemplazar \"S√≠\"/\"No\" por NaN y asegurar tipo num√©rico\n",
    "for col in ['pp07g1', 'pp07g2', 'pp07h']:\n",
    "    if col in df_sel.columns:\n",
    "        df_sel[col] = df_sel[col].replace({'S√≠': np.nan, 'No': np.nan})\n",
    "        df_sel[col] = pd.to_numeric(df_sel[col], errors='coerce')\n",
    "\n",
    "# Recorte de valores extremos del IPCF (percentiles 1 y 99)\n",
    "p1, p99 = df_sel['ipcf'].quantile([0.01, 0.99])\n",
    "df_sel.loc[(df_sel['ipcf'] < p1) | (df_sel['ipcf'] > p99), 'ipcf'] = np.nan\n",
    "\n",
    "print(\"‚úÖ Limpieza final aplicada.\")\n",
    "print(df_sel.describe(include='all').T.loc[['ipcf','pp07g1','pp07g2','pp07h']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dcd84e-cf50-43ef-8a59-43ed25cbeb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Ver aglomerados del a√±o 2005 ===\n",
    "df_union['region'].unique()\n",
    "df_union['aglomerado'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa736738-59e4-4433-a5a3-cda1c0ab5ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Ver aglomerados del a√±o 2025 ===\n",
    "df_union[df_union['anio'] == 2025]['aglomerado'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea08da07-10c6-441e-844a-a65d754c7efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Filtrar aglomerado seleccionado ===\n",
    "aglomerado_sel = 'Partidos del GBA'\n",
    "df_reg = df_union[df_union['aglomerado'] == aglomerado_sel].copy()\n",
    "\n",
    "print(f\"Aglomerado seleccionado: {aglomerado_sel}\")\n",
    "print(\"Filas:\", df_reg.shape[0])\n",
    "print(\"A√±os disponibles:\", df_reg['anio'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0386a8a4-7c29-451b-994d-83a79fd519d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar distribuci√≥n de c√≥digos de aglomerado en 2025\n",
    "df_union[df_union['anio'] == 2025]['aglomerado'].value_counts().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef690a80-4d0e-4ae4-8183-d9d7c52756a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar correspondencia entre aglomerado y regi√≥n para 2025\n",
    "df_2025 = df_union[df_union['anio'] == 2025][['aglomerado', 'region']].drop_duplicates()\n",
    "print(df_2025.sort_values('aglomerado').head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf7d2a8-c64f-4f73-9434-34f35858a241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar los nombres de regi√≥n y aglomerado en 2025\n",
    "# REGION (N)\tC√≥digo de regi√≥n macroecon√≥mica\t01 = Gran Buenos Aires ‚úÖ\n",
    "# AGLOMERADO (N)\tC√≥digo de aglomerado dentro de cada regi√≥n\t33 = Partidos del Gran Buenos Aires ‚úÖ\n",
    "\n",
    "df_2025 = df_union[df_union['anio'] == 2025][['region', 'aglomerado']].drop_duplicates()\n",
    "df_2025.sort_values('aglomerado')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddac896-94af-4c36-895d-82b06dac8e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Selecci√≥n coherente de Partidos del Gran Buenos Aires (2005 y 2025) ===\n",
    "\n",
    "df_reg = df_union[\n",
    "    (df_union['aglomerado'].isin(['Partidos del GBA', 33])) |\n",
    "    (df_union['region'].isin([1]))  # seguridad extra si hay codificaci√≥n num√©rica\n",
    "].copy()\n",
    "\n",
    "print(\"‚úÖ Regi√≥n/Aglomerado seleccionado: Partidos del Gran Buenos Aires (GBA)\")\n",
    "print(\"Filas totales:\", df_reg.shape[0])\n",
    "print(\"A√±os disponibles:\", df_reg['anio'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d53174c-11f3-46d7-b5d4-99029a6823e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg['nivel_ed'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f650229-d27a-48d3-a16d-98e5acbaae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_reg.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3912375-c922-48b4-a135-74676073d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_reg['nivel_ed'].unique()[:20])\n",
    "print(df_reg['nivel_ed'].value_counts(dropna=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a7ac0-dbc2-47af-835c-0631c18f70ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_reg['nivel_ed'].dropna().unique()[:20])\n",
    "print(df_reg['nivel_ed'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062f6d75-aef9-446b-8f3e-0d6918f00c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(data=df_reg, x='ch04', hue='anio')\n",
    "plt.title(\"Distribuci√≥n por sexo - GBA 2005 vs 2025\")\n",
    "plt.xlabel(\"Sexo (ch04)\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca84b2af-6ce6-4504-a40d-e21db923a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Composici√≥n por sexo (%) - versi√≥n robusta ---\n",
    "tmp = df_reg.copy()\n",
    "\n",
    "# Normalizar ch04 a texto en todos los a√±os\n",
    "tmp[\"ch04\"] = (\n",
    "    tmp[\"ch04\"]\n",
    "    .replace({1: \"Var√≥n\", 2: \"Mujer\", \"1\": \"Var√≥n\", \"2\": \"Mujer\"})\n",
    "    .fillna(\"Sin dato\")\n",
    ")\n",
    "\n",
    "# Tabla de porcentajes por a√±o\n",
    "prop_df = (\n",
    "    tmp.groupby([\"anio\", \"ch04\"])\n",
    "       .size()\n",
    "       .groupby(level=0, group_keys=False)\n",
    "       .apply(lambda x: x / x.sum() * 100)\n",
    "       .reset_index(name=\"Porcentaje\")\n",
    ")\n",
    "\n",
    "# Forzar tipos/orden para asegurar colores correctos\n",
    "prop_df[\"anio\"] = prop_df[\"anio\"].astype(str)  # \"2005\", \"2025\"\n",
    "hue_order = [\"2005\", \"2025\"]\n",
    "x_order   = [\"Var√≥n\", \"Mujer\"]  # orden deseado en el eje X\n",
    "palette   = {\"2005\": \"#B2B2B2\", \"2025\": \"#4B4A67\"}\n",
    "\n",
    "# Gr√°fico\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.barplot(\n",
    "    data=prop_df,\n",
    "    x=\"ch04\", y=\"Porcentaje\", hue=\"anio\",\n",
    "    order=x_order, hue_order=hue_order,\n",
    "    palette=palette, errorbar=None\n",
    ")\n",
    "plt.title(\"Composici√≥n por sexo (%) - GBA 2005 vs 2025\", fontsize=12, weight=\"bold\")\n",
    "plt.xlabel(\"Sexo\")\n",
    "plt.ylabel(\"Porcentaje\")\n",
    "plt.legend(title=\"A√±o\", loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"FIGURAS/composicion_sexo_porcentaje.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428a0549-8d12-432e-bb53-7f09389bab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === INCISO 4 - MATRIZ DE CORRELACI√ìN (EPH GBA 2005 vs 2025) ===\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.makedirs(\"FIGURAS\", exist_ok=True)\n",
    "\n",
    "# Variables de inter√©s\n",
    "vars_corr = [\"ch04\", \"ch06\", \"ch07\", \"ch08\", \"nivel_ed\", \"estado\", \"cat_inac\", \"ipcf\"]\n",
    "\n",
    "# Subconjuntos\n",
    "df_2005 = df_reg[df_reg[\"anio\"] == 2005][vars_corr].copy()\n",
    "df_2025 = df_reg[df_reg[\"anio\"] == 2025][vars_corr].copy()\n",
    "\n",
    "# Convertir variables num√©ricas\n",
    "for col in [\"ch06\", \"ipcf\"]:\n",
    "    df_2005[col] = pd.to_numeric(df_2005[col], errors=\"coerce\")\n",
    "    df_2025[col] = pd.to_numeric(df_2025[col], errors=\"coerce\")\n",
    "\n",
    "# Crear variables dummies sin drop_first para mostrar todas las categor√≠as\n",
    "df_2005_dummies = pd.get_dummies(df_2005, columns=[\"ch04\",\"ch07\",\"ch08\",\"nivel_ed\",\"estado\",\"cat_inac\"], drop_first=False)\n",
    "df_2025_dummies = pd.get_dummies(df_2025, columns=[\"ch04\",\"ch07\",\"ch08\",\"nivel_ed\",\"estado\",\"cat_inac\"], drop_first=False)\n",
    "\n",
    "# Calcular matrices de correlaci√≥n\n",
    "corr_2005 = df_2005_dummies.corr(numeric_only=True)\n",
    "corr_2025 = df_2025_dummies.corr(numeric_only=True)\n",
    "\n",
    "# --- Gr√°ficos en disposici√≥n vertical ---\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 18))  # 2 filas, 1 columna\n",
    "\n",
    "# Matriz 2005\n",
    "sns.heatmap(corr_2005, ax=axes[0], cmap=\"coolwarm\", center=0, cbar=False)\n",
    "axes[0].set_title(\"Matriz de correlaci√≥n - EPH 2005 (GBA)\", fontsize=14, weight=\"bold\")\n",
    "axes[0].tick_params(axis='x', rotation=90, labelsize=8)\n",
    "axes[0].tick_params(axis='y', labelsize=8)\n",
    "\n",
    "# Matriz 2025\n",
    "sns.heatmap(corr_2025, ax=axes[1], cmap=\"coolwarm\", center=0, cbar=False)\n",
    "axes[1].set_title(\"Matriz de correlaci√≥n - EPH 2025 (GBA)\", fontsize=14, weight=\"bold\")\n",
    "axes[1].tick_params(axis='x', rotation=90, labelsize=8)\n",
    "axes[1].tick_params(axis='y', labelsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"FIGURAS/correlacion_2005_2025_vertical.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edd8bf1-85b6-4aae-90f1-d465e923e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === INCISO 4 - MATRIZ DE CORRELACI√ìN EPH GBA 2005 vs 2025 ===\n",
    "import pandas as pd, numpy as np, seaborn as sns, matplotlib.pyplot as plt, os\n",
    "\n",
    "os.makedirs(\"FIGURAS\", exist_ok=True)\n",
    "\n",
    "vars_corr = [\"ch04\",\"ch06\",\"ch07\",\"ch08\",\"nivel_ed\",\"estado\",\"cat_inac\",\"ipcf\"]\n",
    "\n",
    "# Filtrar por a√±o\n",
    "df_2005 = df_reg.loc[df_reg[\"anio\"] == 2005, vars_corr].copy()\n",
    "df_2025 = df_reg.loc[df_reg[\"anio\"] == 2025, vars_corr].copy()\n",
    "\n",
    "# --- Limpieza: reemplazar c√≥digos inv√°lidos o Ns/Nr ---\n",
    "invalid_map = {\n",
    "    \"ch04\": [9],\n",
    "    \"ch07\": [0, 9],\n",
    "    \"ch08\": [0, 9],\n",
    "    \"nivel_ed\": [0, 9],\n",
    "    \"estado\": [0, 9],\n",
    "    \"cat_inac\": [0, 9]\n",
    "}\n",
    "\n",
    "for df in [df_2005, df_2025]:\n",
    "    for col, invalid_vals in invalid_map.items():\n",
    "        df[col] = df[col].replace(invalid_vals, np.nan)\n",
    "\n",
    "# --- Convertir a num√©ricas las continuas ---\n",
    "for col in [\"ch06\", \"ipcf\"]:\n",
    "    df_2005[col] = pd.to_numeric(df_2005[col], errors=\"coerce\")\n",
    "    df_2025[col] = pd.to_numeric(df_2025[col], errors=\"coerce\")\n",
    "\n",
    "# --- Crear variables dummies legibles ---\n",
    "map_prefix = {\n",
    "    \"ch04\": \"Sexo\",\n",
    "    \"ch06\": \"Edad\",\n",
    "    \"ch07\": \"EstadoCivil\",\n",
    "    \"ch08\": \"CoberturaSalud\",\n",
    "    \"nivel_ed\": \"Educacion\",\n",
    "    \"estado\": \"Actividad\",\n",
    "    \"cat_inac\": \"Inactividad\",\n",
    "    \"ipcf\": \"IngresoPerCapita\"\n",
    "}\n",
    "\n",
    "# Reorganizar: dummies solo para las categ√≥ricas\n",
    "cats = [\"ch04\",\"ch07\",\"ch08\",\"nivel_ed\",\"estado\",\"cat_inac\"]\n",
    "\n",
    "df_2005_dum = pd.get_dummies(\n",
    "    df_2005,\n",
    "    columns=cats,\n",
    "    prefix=[map_prefix[k] for k in cats],\n",
    "    drop_first=False\n",
    ").rename(columns={\"ch06\": \"Edad\", \"ipcf\": \"IngresoPerCapita\"})\n",
    "\n",
    "df_2025_dum = pd.get_dummies(\n",
    "    df_2025,\n",
    "    columns=cats,\n",
    "    prefix=[map_prefix[k] for k in cats],\n",
    "    drop_first=False\n",
    ").rename(columns={\"ch06\": \"Edad\", \"ipcf\": \"IngresoPerCapita\"})\n",
    "\n",
    "# --- Calcular correlaciones ---\n",
    "corr_2005 = df_2005_dum.corr(numeric_only=True)\n",
    "corr_2025 = df_2025_dum.corr(numeric_only=True)\n",
    "\n",
    "# --- Graficar heatmaps (verticales) ---\n",
    "fig, axes = plt.subplots(2, 1, figsize=(13, 18))\n",
    "\n",
    "sns.heatmap(corr_2005, ax=axes[0], cmap=\"coolwarm\", center=0, cbar=False)\n",
    "axes[0].set_title(\"Matriz de correlaci√≥n - EPH 2005 (GBA)\", fontsize=14, weight=\"bold\")\n",
    "axes[0].tick_params(axis='x', rotation=90, labelsize=8)\n",
    "axes[0].tick_params(axis='y', labelsize=8)\n",
    "\n",
    "sns.heatmap(corr_2025, ax=axes[1], cmap=\"coolwarm\", center=0, cbar=False)\n",
    "axes[1].set_title(\"Matriz de correlaci√≥n - EPH 2025 (GBA)\", fontsize=14, weight=\"bold\")\n",
    "axes[1].tick_params(axis='x', rotation=90, labelsize=8)\n",
    "axes[1].tick_params(axis='y', labelsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"FIGURAS/correlacion_eph_2005_2025_final.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c71362e-428e-48ec-8b55-0b272c0597c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === INCISO 5 - An√°lisis de no respuesta en condici√≥n de actividad e ingreso ===\n",
    "import os\n",
    "\n",
    "# Asegurar que exista la carpeta de salida\n",
    "os.makedirs(\"BASES\", exist_ok=True)\n",
    "\n",
    "# Contar no respuestas en condici√≥n de actividad\n",
    "noresp_actividad = df_reg[df_reg[\"estado\"].isin([0, 9])].groupby(\"anio\").size()\n",
    "print(\"Personas sin respuesta sobre condici√≥n de actividad:\")\n",
    "print(noresp_actividad)\n",
    "\n",
    "# Crear subconjuntos seg√∫n respuesta de ingreso total familiar (ITF)\n",
    "respondieron = df_reg[df_reg[\"itf\"] > 0].copy()\n",
    "norespondieron = df_reg[(df_reg[\"itf\"] == 0) | (df_reg[\"itf\"].isna())].copy()\n",
    "\n",
    "# Guardar dimensiones\n",
    "print(\"\\nDimensiones:\")\n",
    "print(\"Respondieron:\", respondieron.shape)\n",
    "print(\"No respondieron:\", norespondieron.shape)\n",
    "\n",
    "# Guardar bases intermedias (opcional)\n",
    "respondieron.to_csv(\"BASES/respondieron.csv\", index=False)\n",
    "norespondieron.to_csv(\"BASES/norespondieron.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1f3196-5428-48e0-a14f-c3eb1958f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === INCISO 5 - An√°lisis de no respuesta en condici√≥n de actividad e ingreso (2005 vs 2025) ===\n",
    "import os\n",
    "os.makedirs(\"BASES\", exist_ok=True)\n",
    "\n",
    "# --- 1. Personas sin respuesta sobre CONDICI√ìN DE ACTIVIDAD ---\n",
    "# Se consideran c√≥digos 0, 9 o valores faltantes (NaN)\n",
    "noresp_actividad = (\n",
    "    df_reg[df_reg[\"estado\"].isin([0, 9]) | df_reg[\"estado\"].isna()]\n",
    "    .groupby(\"anio\")\n",
    "    .size()\n",
    ")\n",
    "print(\"Personas sin respuesta sobre condici√≥n de actividad (por a√±o):\")\n",
    "print(noresp_actividad)\n",
    "\n",
    "# --- 2. Separar bases seg√∫n respuesta de INGRESO TOTAL FAMILIAR ---\n",
    "respondieron = df_reg[df_reg[\"itf\"] > 0].copy()\n",
    "norespondieron = df_reg[(df_reg[\"itf\"] == 0) | (df_reg[\"itf\"].isna())].copy()\n",
    "\n",
    "# --- 3. Contar por a√±o ---\n",
    "resp_por_anio = respondieron.groupby(\"anio\").size()\n",
    "noresp_por_anio = norespondieron.groupby(\"anio\").size()\n",
    "\n",
    "print(\"\\nCantidad de personas que RESPONDIERON ITF (por a√±o):\")\n",
    "print(resp_por_anio)\n",
    "print(\"\\nCantidad de personas que NO RESPONDIERON ITF (por a√±o):\")\n",
    "print(noresp_por_anio)\n",
    "\n",
    "# --- 4. Guardar resultados ---\n",
    "respondieron.to_csv(\"BASES/respondieron.csv\", index=False)\n",
    "norespondieron.to_csv(\"BASES/norespondieron.csv\", index=False)\n",
    "\n",
    "print(\"\\nBases exportadas correctamente a la carpeta BASES/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469213ae-7243-470a-94d6-398566a9da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === INCISO 5 - An√°lisis de no respuesta: Condici√≥n de actividad e ingreso familiar ===\n",
    "\n",
    "import pandas as pd, numpy as np, os\n",
    "\n",
    "# Crear carpeta de salida\n",
    "os.makedirs(\"BASES\", exist_ok=True)\n",
    "\n",
    "# --- 1. Detecci√≥n de la variable correcta para condici√≥n de actividad ---\n",
    "# Algunas bases 2005 usan 'cat_ocup' en lugar de 'estado'\n",
    "if \"estado\" in df_reg.columns:\n",
    "    var_act = \"estado\"\n",
    "elif \"cat_ocup\" in df_reg.columns:\n",
    "    var_act = \"cat_ocup\"\n",
    "else:\n",
    "    raise ValueError(\"No se encontr√≥ la variable de condici√≥n de actividad (estado o cat_ocup).\")\n",
    "\n",
    "# --- 2. Personas sin respuesta en condici√≥n de actividad ---\n",
    "# C√≥digos de no respuesta (0, 9 o valores faltantes)\n",
    "noresp_actividad = (\n",
    "    df_reg[\n",
    "        (df_reg[var_act].isin([0, 9])) | (df_reg[var_act].isna()) | (df_reg[var_act] == \" \")\n",
    "    ]\n",
    "    .groupby(\"anio\")\n",
    "    .size()\n",
    ")\n",
    "\n",
    "print(\"Personas sin respuesta sobre condici√≥n de actividad (por a√±o):\")\n",
    "print(noresp_actividad)\n",
    "\n",
    "# --- 3. Separar bases seg√∫n respuesta de ingreso total familiar ---\n",
    "respondieron = df_reg[df_reg[\"itf\"] > 0].copy()\n",
    "norespondieron = df_reg[(df_reg[\"itf\"] == 0) | (df_reg[\"itf\"].isna())].copy()\n",
    "\n",
    "# --- 4. Conteo resumido por a√±o ---\n",
    "resp_por_anio = respondieron.groupby(\"anio\").size()\n",
    "noresp_por_anio = norespondieron.groupby(\"anio\").size()\n",
    "\n",
    "print(\"\\nCantidad de personas que RESPONDIERON ITF (por a√±o):\")\n",
    "print(resp_por_anio)\n",
    "print(\"\\nCantidad de personas que NO RESPONDIERON ITF (por a√±o):\")\n",
    "print(noresp_por_anio)\n",
    "\n",
    "# --- 5. Guardar las bases intermedias ---\n",
    "respondieron.to_csv(\"BASES/respondieron.csv\", index=False)\n",
    "norespondieron.to_csv(\"BASES/norespondieron.csv\", index=False)\n",
    "\n",
    "print(\"\\nBases exportadas correctamente a la carpeta BASES/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af96547-eee8-4ac2-85e6-ee76488ff339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "noresp_por_anio = pd.DataFrame({\n",
    "    \"Respondieron\": resp_por_anio,\n",
    "    \"No respondieron\": noresp_por_anio\n",
    "})\n",
    "\n",
    "noresp_por_anio.plot(\n",
    "    kind=\"bar\",\n",
    "    stacked=True,\n",
    "    color=[\"#4CAF50\", \"#F44336\"],\n",
    "    figsize=(7,4)\n",
    ")\n",
    "\n",
    "plt.title(\"Respuestas sobre ingreso total familiar (ITF) por a√±o - GBA\")\n",
    "plt.xlabel(\"A√±o\")\n",
    "plt.ylabel(\"Cantidad de personas\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe87cd2-42e4-41ba-9041-005d1ebf2a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo con el path que encontraste\n",
    "path_tabla = r\"C:\\Users\\julla\\Downloads\\Datos\\tabla_adulto_equiv.xlsx\"\n",
    "\n",
    "tabla_equiv = pd.read_excel(path_tabla)\n",
    "\n",
    "# Mostrar informaci√≥n general\n",
    "print(\"=== INFORMACI√ìN GENERAL DE LA TABLA DE EQUIVALENCIAS ===\")\n",
    "print(tabla_equiv.info(), \"\\n\")\n",
    "\n",
    "# Mostrar las primeras filas\n",
    "print(\"=== PRIMERAS FILAS DE LA TABLA ===\")\n",
    "print(tabla_equiv.head(10))\n",
    "\n",
    "# Mostrar nombres de columnas exactos (para saber c√≥mo mapearlos luego)\n",
    "print(\"\\n=== NOMBRES DE COLUMNAS ===\")\n",
    "print(list(tabla_equiv.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbec4dfe-6f37-4a23-892c-279698c3dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(respondieron[\"ch04\"].unique()[:20])\n",
    "print(respondieron[\"ch04\"].value_counts(dropna=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d73db55-1b3f-42c8-ba15-94159d0187d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CORREGIDO: Lectura robusta de tabla_adulto_equiv.xlsx ===\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "path_equiv = r\"C:\\Users\\julla\\Downloads\\Datos\\tabla_adulto_equiv.xlsx\"\n",
    "\n",
    "# Cargar todo sin encabezado\n",
    "tabla_equiv_raw = pd.read_excel(path_equiv, header=None)\n",
    "\n",
    "# Buscar fila donde empiece \"Edad\"\n",
    "idx_inicio = tabla_equiv_raw[\n",
    "    tabla_equiv_raw.iloc[:,0].astype(str).str.contains(\"Edad\", case=False, na=False)\n",
    "].index[0] + 1\n",
    "\n",
    "# Extraer solo las tres columnas (Edad, Mujeres, Varones)\n",
    "tabla_equiv = tabla_equiv_raw.iloc[idx_inicio:, [0,1,2]].copy()\n",
    "tabla_equiv.columns = [\"edad\", \"mujeres\", \"varones\"]\n",
    "\n",
    "# üîπ LIMPIEZA ROBUSTA\n",
    "tabla_equiv = tabla_equiv.dropna(subset=[\"edad\"])             # eliminar filas vac√≠as\n",
    "tabla_equiv = tabla_equiv[~tabla_equiv[\"edad\"].str.contains(\"Menor\", na=False)]  # quitar textos\n",
    "tabla_equiv = tabla_equiv[~tabla_equiv[\"edad\"].str.contains(\"Edad\", na=False)]   # quitar encabezados residuales\n",
    "\n",
    "# Quitar la palabra \"a√±os\" y convertir a num√©rico solo cuando sea posible\n",
    "tabla_equiv[\"edad\"] = (\n",
    "    tabla_equiv[\"edad\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\" a√±os\",\"\", regex=False)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# Filtrar solo filas donde edad es num√©rica\n",
    "tabla_equiv = tabla_equiv[tabla_equiv[\"edad\"].str.match(r\"^\\d+$\")]\n",
    "tabla_equiv[\"edad\"] = tabla_equiv[\"edad\"].astype(int)\n",
    "\n",
    "# Convertir valores de mujeres y varones a num√©ricos\n",
    "tabla_equiv[\"mujeres\"] = pd.to_numeric(tabla_equiv[\"mujeres\"], errors=\"coerce\")\n",
    "tabla_equiv[\"varones\"] = pd.to_numeric(tabla_equiv[\"varones\"], errors=\"coerce\")\n",
    "\n",
    "# Mostrar verificaci√≥n\n",
    "print(\"‚úÖ Tabla limpia y num√©rica:\")\n",
    "print(tabla_equiv.head(10))\n",
    "print(\"\\nColumnas:\", tabla_equiv.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb2dca-6f47-46a4-b380-5b1b90706c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(respondieron[\"ch04\"].unique()[:20])\n",
    "print(respondieron[\"ch04\"].value_counts(dropna=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4622bacb-d155-4875-acdb-0d01ec9342a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === REPARAR VARIABLE ch04 (sexo) PARA 2005 ===\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1Ô∏è‚É£ Cargar base \"respondieron\" actual ---\n",
    "respondieron = pd.read_csv(\"BASES/respondieron.csv\", low_memory=False)\n",
    "respondieron.columns = respondieron.columns.str.lower()\n",
    "\n",
    "# --- 2Ô∏è‚É£ Cargar base original del 2005 (archivo .dta) ---\n",
    "base_2005 = pd.read_stata(r\"C:\\Users\\julla\\Downloads\\Datos\\Individual_t105.dta\")\n",
    "base_2005.columns = base_2005.columns.str.lower()\n",
    "\n",
    "print(\"Columnas en base 2005:\", [c for c in base_2005.columns if \"ch\" in c or \"hogar\" in c or \"codusu\" in c][:12])\n",
    "\n",
    "# --- 3Ô∏è‚É£ Filtrar solo variables necesarias para merge ---\n",
    "cols_merge = [c for c in [\"codusu\", \"nro_hogar\", \"componente\", \"ch04\"] if c in base_2005.columns]\n",
    "base_2005_sub = base_2005[cols_merge].copy()\n",
    "\n",
    "# --- 4Ô∏è‚É£ Combinar para reinyectar el sexo en respondieron ---\n",
    "respondieron = respondieron.merge(\n",
    "    base_2005_sub,\n",
    "    on=[\"codusu\", \"nro_hogar\", \"componente\"],\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_from2005\")\n",
    ")\n",
    "\n",
    "# Si ch04 est√° vac√≠o en respondieron, usar el valor de la base 2005\n",
    "respondieron[\"ch04\"] = respondieron[\"ch04\"].fillna(respondieron[\"ch04_from2005\"])\n",
    "respondieron.drop(columns=[\"ch04_from2005\"], inplace=True)\n",
    "\n",
    "# --- 5Ô∏è‚É£ Guardar resultado intermedio ---\n",
    "respondieron.to_csv(\"BASES/respondieron_reparado.csv\", index=False)\n",
    "print(\"\\n‚úÖ Variable 'ch04' restaurada correctamente desde Individual_t105.dta\")\n",
    "print(\"Archivo generado: BASES/respondieron_reparado.csv\")\n",
    "print(respondieron[[\"anio\", \"ch04\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fcda20-a9d4-454d-9ef2-311d82bdce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === INCISO 6 ‚Äì C√°lculo de adulto equivalente y suma por hogar ===\n",
    "import pandas as pd, numpy as np, os\n",
    "\n",
    "# --- 1Ô∏è‚É£ Crear tabla manual de equivalencias basada en el INDEC ---\n",
    "tabla_equiv = pd.DataFrame({\n",
    "    \"edad_min\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 30, 46, 61, 76],\n",
    "    \"edad_max\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 29, 45, 60, 75, 120],\n",
    "    \"mujeres\": [0.35, 0.37, 0.46, 0.51, 0.55, 0.60, 0.64, 0.66, 0.68, 0.69, 0.70, 0.72, 0.74, 0.76, 0.76, 0.77, 0.77, 0.77, 0.76, 0.77, 0.76, 0.67, 0.63],\n",
    "    \"varones\": [0.35, 0.37, 0.46, 0.51, 0.55, 0.60, 0.64, 0.66, 0.68, 0.69, 0.79, 0.82, 0.85, 0.90, 0.96, 1.00, 1.03, 1.04, 1.02, 1.00, 1.00, 0.83, 0.74]\n",
    "})\n",
    "\n",
    "# Pasar a formato largo\n",
    "tabla_equiv_long = tabla_equiv.melt(\n",
    "    id_vars=[\"edad_min\", \"edad_max\"],\n",
    "    var_name=\"sexo_txt\",\n",
    "    value_name=\"adulto_equiv\"\n",
    ")\n",
    "\n",
    "# Asignar c√≥digos EPH (1 = var√≥n, 2 = mujer)\n",
    "tabla_equiv_long[\"sexo\"] = tabla_equiv_long[\"sexo_txt\"].map({\"mujeres\": 2, \"varones\": 1})\n",
    "tabla_equiv_long = tabla_equiv_long[[\"edad_min\", \"edad_max\", \"sexo\", \"adulto_equiv\"]]\n",
    "\n",
    "print(\"Vista previa de tabla_equiv_long:\")\n",
    "print(tabla_equiv_long.head(10))\n",
    "\n",
    "# --- 2Ô∏è‚É£ Cargar base respondieron ---\n",
    "respondieron = pd.read_csv(\"BASES/respondieron_reparado.csv\", low_memory=False)\n",
    "respondieron.columns = respondieron.columns.str.lower()\n",
    "\n",
    "# --- üîß Normalizar variable ch04 a formato num√©rico (1 = var√≥n, 2 = mujer) ---\n",
    "respondieron[\"ch04\"] = (\n",
    "    respondieron[\"ch04\"]\n",
    "    .replace({\"Var√≥n\": 1, \"Mujer\": 2, \"varon\": 1, \"mujer\": 2})\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# Convertir variables relevantes\n",
    "respondieron[\"ch04\"] = pd.to_numeric(respondieron[\"ch04\"], errors=\"coerce\")  # sexo\n",
    "respondieron[\"ch06\"] = pd.to_numeric(respondieron[\"ch06\"], errors=\"coerce\")  # edad\n",
    "\n",
    "# --- 3Ô∏è‚É£ Asignar valor adulto_equiv seg√∫n rango de edad y sexo ---\n",
    "def buscar_equiv(edad, sexo):\n",
    "    \"\"\"Devuelve el adulto_equiv correspondiente al rango de edad y sexo.\"\"\"\n",
    "    if pd.isna(edad) or pd.isna(sexo):\n",
    "        return np.nan\n",
    "    fila = tabla_equiv_long[\n",
    "        (tabla_equiv_long[\"sexo\"] == int(sexo)) &\n",
    "        (edad >= tabla_equiv_long[\"edad_min\"]) &\n",
    "        (edad <= tabla_equiv_long[\"edad_max\"])\n",
    "    ]\n",
    "    return fila[\"adulto_equiv\"].iloc[0] if not fila.empty else np.nan\n",
    "\n",
    "respondieron[\"adulto_equiv\"] = respondieron.apply(\n",
    "    lambda row: buscar_equiv(row[\"ch06\"], row[\"ch04\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# --- 4Ô∏è‚É£ Calcular total por hogar ---\n",
    "respondieron[\"codusu\"] = respondieron[\"codusu\"].astype(str)\n",
    "respondieron[\"nro_hogar\"] = respondieron[\"nro_hogar\"].astype(str)\n",
    "respondieron[\"id_hogar\"] = respondieron[\"codusu\"] + \"_\" + respondieron[\"nro_hogar\"]\n",
    "\n",
    "adultos_equiv_hogar = (\n",
    "    respondieron.groupby(\"id_hogar\")[\"adulto_equiv\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"adulto_equiv\": \"ad_equiv_hogar\"})\n",
    ")\n",
    "\n",
    "respondieron = respondieron.merge(adultos_equiv_hogar, on=\"id_hogar\", how=\"left\")\n",
    "\n",
    "# --- 5Ô∏è‚É£ Guardar resultado final ---\n",
    "os.makedirs(\"BASES\", exist_ok=True)\n",
    "respondieron.to_csv(\"BASES/respondieron_equiv.csv\", index=False)\n",
    "\n",
    "print(\"\\n‚úÖ Archivo final generado: BASES/respondieron_equiv.csv\")\n",
    "print(\"Columnas agregadas: adulto_equiv, ad_equiv_hogar\")\n",
    "\n",
    "# --- 6Ô∏è‚É£ Verificar resultados por a√±o ---\n",
    "print(respondieron.groupby(\"anio\")[\"adulto_equiv\"].agg([\"count\", \"mean\", \"min\", \"max\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755ff305-4ae0-4b4c-8b38-4d52db1e0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(respondieron[\"adulto_equiv\"].describe())\n",
    "print(\"\\nPorcentaje de valores faltantes en adulto_equiv:\",\n",
    "      respondieron[\"adulto_equiv\"].isna().mean().round(3) * 100, \"%\")\n",
    "\n",
    "print(\"\\nEjemplo de hogares con m√°s de 3 adultos equivalentes:\")\n",
    "print(respondieron[respondieron[\"ad_equiv_hogar\"] > 3][[\"anio\", \"id_hogar\", \"ad_equiv_hogar\"]].drop_duplicates().head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ce3c2f-c930-464b-adf3-f62effa0b6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === INCISO 7 ‚Äì Ingreso necesario por hogar seg√∫n la Canasta B√°sica Total ===\n",
    "import pandas as pd, os\n",
    "\n",
    "# Cargar base con equivalencias\n",
    "respondieron = pd.read_csv(\"BASES/respondieron_equiv.csv\", low_memory=False)\n",
    "\n",
    "# Definir valores de la Canasta B√°sica Total por adulto equivalente\n",
    "CBT = {2005: 205.07, 2025: 365177}\n",
    "\n",
    "# Asignar la CBT correspondiente a cada a√±o\n",
    "respondieron[\"cbt_equiv\"] = respondieron[\"anio\"].map(CBT)\n",
    "\n",
    "# Calcular ingreso necesario del hogar\n",
    "respondieron[\"ingreso_necesario\"] = respondieron[\"cbt_equiv\"] * respondieron[\"ad_equiv_hogar\"]\n",
    "\n",
    "# Guardar nueva versi√≥n\n",
    "os.makedirs(\"BASES\", exist_ok=True)\n",
    "respondieron.to_csv(\"BASES/respondieron_ingreso_necesario.csv\", index=False)\n",
    "\n",
    "# --- Resumen de validaci√≥n ---\n",
    "print(\"\\n‚úÖ Archivo actualizado: BASES/respondieron_ingreso_necesario.csv\")\n",
    "print(\"Columnas nuevas: cbt_equiv, ingreso_necesario\\n\")\n",
    "\n",
    "# Mostrar algunas filas de ejemplo\n",
    "print(respondieron[[\"anio\", \"id_hogar\", \"ad_equiv_hogar\", \"cbt_equiv\", \"ingreso_necesario\"]].sample(10))\n",
    "\n",
    "# Verificar rango de valores por a√±o\n",
    "print(\"\\nResumen por a√±o:\")\n",
    "print(respondieron.groupby(\"anio\")[\"ingreso_necesario\"].agg([\"min\", \"mean\", \"max\"]).round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ead4dbd-4456-4c10-b8f9-d917ec1a581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === AN√ÅLISIS DE ADULTOS EQUIVALENTES POR HOGAR (2005 vs 2025) ===\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Cargar base con ad_equiv_hogar e ingreso_necesario\n",
    "df = pd.read_csv(\"BASES/respondieron_ingreso_necesario.csv\", low_memory=False)\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "# Sanity checks m√≠nimos\n",
    "assert {\"anio\", \"ad_equiv_hogar\"}.issubset(df.columns), \"Faltan columnas clave\"\n",
    "df = df.copy()\n",
    "df[\"ad_equiv_hogar\"] = pd.to_numeric(df[\"ad_equiv_hogar\"], errors=\"coerce\")\n",
    "df[\"anio\"] = pd.to_numeric(df[\"anio\"], errors=\"coerce\")\n",
    "\n",
    "# 2) Resumen por a√±o (no winsorizado)\n",
    "resumen = (\n",
    "    df.groupby(\"anio\", observed=False)[\"ad_equiv_hogar\"]\n",
    "      .agg(n=\"count\", mean=\"mean\", median=\"median\",\n",
    "           p10=lambda s: s.quantile(0.10),\n",
    "           p25=lambda s: s.quantile(0.25),\n",
    "           p75=lambda s: s.quantile(0.75),\n",
    "           p90=lambda s: s.quantile(0.90),\n",
    "           max=\"max\")\n",
    "      .round(3)\n",
    ")\n",
    "print(\"=== Resumen por a√±o (ad_equiv_hogar, sin winsorizar) ===\")\n",
    "print(resumen, \"\\n\")\n",
    "\n",
    "# 3) Umbrales de outliers (p99 por a√±o) y winsorizaci√≥n\n",
    "p99 = df.groupby(\"anio\", observed=False)[\"ad_equiv_hogar\"].quantile(0.99)\n",
    "df = df.merge(p99.rename(\"p99\"), on=\"anio\", how=\"left\")\n",
    "df[\"ad_equiv_hogar_w\"] = np.where(\n",
    "    df[\"ad_equiv_hogar\"] > df[\"p99\"], df[\"p99\"], df[\"ad_equiv_hogar\"]\n",
    ")\n",
    "\n",
    "resumen_w = (\n",
    "    df.groupby(\"anio\", observed=False)[\"ad_equiv_hogar_w\"]\n",
    "      .agg(n=\"count\", mean=\"mean\", median=\"median\",\n",
    "           p10=lambda s: s.quantile(0.10),\n",
    "           p25=lambda s: s.quantile(0.25),\n",
    "           p75=lambda s: s.quantile(0.75),\n",
    "           p90=lambda s: s.quantile(0.90),\n",
    "           max=\"max\")\n",
    "      .round(3)\n",
    ")\n",
    "print(\"=== Resumen por a√±o (winsorizado en p99 por a√±o) ===\")\n",
    "print(resumen_w, \"\\n\")\n",
    "\n",
    "# 4) Bandas de tama√±o equivalente\n",
    "bins = [0, 2, 3, 4, 6, np.inf]\n",
    "labels = [\"‚â§2\", \"2‚Äì3\", \"3‚Äì4\", \"4‚Äì6\", \">6\"]\n",
    "df[\"band_ad_eq\"] = pd.cut(df[\"ad_equiv_hogar\"], bins=bins, labels=labels, right=True)\n",
    "\n",
    "dist_bandas = (\n",
    "    df.groupby([\"anio\", \"band_ad_eq\"], observed=False)\n",
    "      .size()\n",
    "      .groupby(level=0).apply(lambda s: (100 * s / s.sum()).round(1))\n",
    "      .unstack(fill_value=0)\n",
    ")\n",
    "print(\"=== Distribuci√≥n % de hogares por bandas de ad_equiv_hogar ===\")\n",
    "print(dist_bandas, \"\\n\")\n",
    "\n",
    "# 5) Gr√°ficos (comparables entre a√±os)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 5a) Densidades winsorizadas\n",
    "plt.figure(figsize=(8, 4))\n",
    "for a, sub in df.dropna(subset=[\"ad_equiv_hogar_w\"]).groupby(\"anio\", observed=False):\n",
    "    sns.kdeplot(sub[\"ad_equiv_hogar_w\"], label=str(a), linewidth=2)\n",
    "plt.title(\"Densidad de adultos equivalentes por hogar (winsorizado p99)\")\n",
    "plt.xlabel(\"Adultos equivalentes del hogar\")\n",
    "plt.ylabel(\"Densidad\")\n",
    "plt.legend(title=\"A√±o\")\n",
    "plt.tight_layout()\n",
    "os.makedirs(\"FIGURAS\", exist_ok=True)\n",
    "plt.savefig(\"FIGURAS/densidad_ad_equiv_hogar_p99.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 5b) Boxplot comparativo\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.boxplot(data=df, x=\"anio\", y=\"ad_equiv_hogar_w\")\n",
    "plt.title(\"Distribuci√≥n de adultos equivalentes por hogar (winsorizado p99)\")\n",
    "plt.xlabel(\"A√±o\")\n",
    "plt.ylabel(\"Adultos equivalentes del hogar\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"FIGURAS/box_ad_equiv_hogar_p99.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 5c) Barras apiladas por bandas (versi√≥n estable y retrocompatible)\n",
    "dist_plot = dist_bandas.copy()\n",
    "dist_plot = dist_plot.reset_index()  # convierte el √≠ndice 'anio' en columna\n",
    "dist_plot = dist_plot.melt(id_vars=\"anio\", var_name=\"banda\", value_name=\"pct\")\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.barplot(data=dist_plot, x=\"anio\", y=\"pct\", hue=\"banda\")\n",
    "plt.title(\"Estructura de hogares por adultos equivalentes (%)\")\n",
    "plt.xlabel(\"A√±o\")\n",
    "plt.ylabel(\"% de hogares\")\n",
    "plt.legend(title=\"Bandas ad_eq\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"FIGURAS/bandas_ad_equiv_hogar.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 6) (Opcional) Chequeo identidad ingreso_necesario / cbt_equiv\n",
    "if {\"ingreso_necesario\", \"cbt_equiv\"}.issubset(df.columns):\n",
    "    df[\"check_cbt\"] = (df[\"ingreso_necesario\"] / df[\"cbt_equiv\"]).round(3)\n",
    "    gap = (df[\"check_cbt\"] - df[\"ad_equiv_hogar\"]).abs().median()\n",
    "    print(f\"Chequeo identidad ingreso_necesario/CBT = ad_equiv_hogar ‚Üí mediana |gap| = {gap:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb4653-99e1-43c0-96de-b341caff31b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 8) Identificaci√≥n de hogares pobres seg√∫n ITF e ingreso_necesario ===\n",
    "\n",
    "# Sanity check\n",
    "assert {\"itf\", \"ingreso_necesario\", \"anio\"}.issubset(df.columns), \"Faltan columnas clave\"\n",
    "\n",
    "# Convertir a num√©rico\n",
    "df[\"itf\"] = pd.to_numeric(df[\"itf\"], errors=\"coerce\")\n",
    "df[\"ingreso_necesario\"] = pd.to_numeric(df[\"ingreso_necesario\"], errors=\"coerce\")\n",
    "\n",
    "# Crear variable binaria\n",
    "df[\"pobre\"] = np.where(df[\"itf\"] < df[\"ingreso_necesario\"], 1, 0)\n",
    "\n",
    "# Resumen por a√±o\n",
    "res_pobreza = (\n",
    "    df.groupby(\"anio\", observed=False)\n",
    "      .agg(\n",
    "          hogares_pobres=(\"pobre\", \"sum\"),\n",
    "          total=(\"pobre\", \"count\"),\n",
    "          pct_pobres=(\"pobre\", lambda s: round(100 * s.sum() / s.count(), 1))\n",
    "      )\n",
    ")\n",
    "print(\"=== Pobreza por a√±o (ITF < ingreso_necesario) ===\")\n",
    "print(res_pobreza, \"\\n\")\n",
    "\n",
    "# Visualizaci√≥n\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(data=res_pobreza.reset_index(), x=\"anio\", y=\"pct_pobres\", color=\"steelblue\")\n",
    "plt.title(\"Porcentaje de hogares pobres seg√∫n ITF vs ingreso necesario\")\n",
    "plt.xlabel(\"A√±o\")\n",
    "plt.ylabel(\"% de hogares pobres\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"FIGURAS/pobreza_por_anio.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb76b7df-b0dd-41ad-b61f-b559b413e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificaci√≥n adicional: raz√≥n ITF / ingreso_necesario\n",
    "df[\"ratio_itf_nec\"] = df[\"itf\"] / df[\"ingreso_necesario\"]\n",
    "\n",
    "res_ratio = (\n",
    "    df.groupby(\"anio\", observed=False)[\"ratio_itf_nec\"]\n",
    "      .agg(media=\"mean\", mediana=\"median\", p25=lambda s: s.quantile(0.25), p75=lambda s: s.quantile(0.75))\n",
    "      .round(2)\n",
    ")\n",
    "print(\"=== Raz√≥n ITF / ingreso_necesario por a√±o ===\")\n",
    "print(res_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4835d5-0f5c-47f8-8d04-653a7c8a0ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 9) Estad√≠sticas descriptivas relevantes de la variable 'pobre' ===\n",
    "\n",
    "# Tabla descriptiva comparando 2005 vs 2025\n",
    "desc_pobre = (\n",
    "    df.groupby(\"anio\", observed=False)\n",
    "      .agg(\n",
    "          pct_pobres=(\"pobre\", lambda s: round(100 * s.mean(), 1)),\n",
    "          media_itf=(\"itf\", \"mean\"),\n",
    "          mediana_itf=(\"itf\", \"median\"),\n",
    "          media_ad_eq=(\"ad_equiv_hogar\", \"mean\"),\n",
    "          mediana_ad_eq=(\"ad_equiv_hogar\", \"median\")\n",
    "      )\n",
    "      .round(2)\n",
    ")\n",
    "print(\"=== Estad√≠sticas descriptivas relevantes de 'pobre' por a√±o ===\")\n",
    "print(desc_pobre, \"\\n\")\n",
    "\n",
    "# 1Ô∏è‚É£ Gr√°fico 1: Distribuci√≥n de pobreza por tama√±o del hogar\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.barplot(data=df, x=\"band_ad_eq\", y=\"pobre\", hue=\"anio\", estimator=np.mean, errorbar=None)\n",
    "plt.title(\"Proporci√≥n de hogares pobres por tama√±o del hogar\")\n",
    "plt.xlabel(\"Adultos equivalentes (bandas)\")\n",
    "plt.ylabel(\"% de hogares pobres\")\n",
    "plt.legend(title=\"A√±o\")\n",
    "plt.gca().yaxis.set_major_formatter(lambda x, pos: f\"{x*100:.0f}%\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"FIGURAS/pobreza_por_tamano_hogar.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 2Ô∏è‚É£ Gr√°fico 2: Boxplot de ITF por condici√≥n de pobreza\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.boxplot(data=df, x=\"pobre\", y=\"itf\", hue=\"anio\")\n",
    "plt.title(\"Distribuci√≥n del ingreso total familiar seg√∫n condici√≥n de pobreza\")\n",
    "plt.xlabel(\"Condici√≥n de pobreza (0 = no pobre, 1 = pobre)\")\n",
    "plt.ylabel(\"Ingreso total familiar (ITF)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"FIGURAS/box_itf_pobre.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 3Ô∏è‚É£ (Opcional) Verificaci√≥n num√©rica r√°pida de pobreza media por tama√±o de hogar\n",
    "check_band = (\n",
    "    df.groupby([\"anio\", \"band_ad_eq\"], observed=False)[\"pobre\"]\n",
    "      .mean()\n",
    "      .unstack()\n",
    "      .round(2)\n",
    ")\n",
    "print(\"=== % de hogares pobres por tama√±o del hogar ===\")\n",
    "print((check_band * 100).fillna(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9137343c-99f3-439d-991c-910b61b749f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
